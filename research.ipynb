{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dropout=0.0, num_attn_blocks=1\n",
      "Encoded gender: [0, 1]\n",
      "Encoded primary_diagnosis: [0, 1, 2, 3, 4]\n",
      "Encoded discharge_to: [0, 1, 2, 3]\n",
      "=== Feature Encoding Complete ===\n",
      "Numerical features: ['age', 'num_procedures', 'days_in_hospital', 'comorbidity_score']\n",
      "Categorical features (encoded): ['gender', 'primary_diagnosis', 'discharge_to']\n",
      "\n",
      "Sample of encoded data:\n",
      "  gender primary_diagnosis discharge_to\n",
      "0      1                 1            1\n",
      "1      1                 3            0\n",
      "2      0                 1            2\n",
      "3      0                 4            0\n",
      "4      0                 2            3\n",
      "ðŸ”„ Applying under sampling with method: tomek\n",
      "=== Applying tomek under sampling ===\n",
      "Original class distribution: {0: 3231, 1: 769}\n",
      "Imbalance ratio: 4.20\n",
      "Applying tomek under sampling...\n",
      "Attempting Tomek Links under sampling...\n",
      "After Tomek Links: 3646 samples\n",
      "Removed 354 samples\n",
      "New class distribution: {0: 2877, 1: 769}\n",
      "=== Under sampling results ===\n",
      "Final class distribution: {0: 2877, 1: 769}\n",
      "Training set size: 4000 -> 3646\n",
      "Samples removed: 354\n",
      "âœ… Under sampling successful using tomek method\n",
      "After under sampling - Training set size: 3646 (was 4000)\n",
      "train_df_train_csv shape after DataFrame creation: (3646, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 750.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train_df_train_csv_processed shape: (3646, 7)\n",
      "Final test_df_train_csv_processed shape: (1000, 7)\n",
      "=== END PREPROCESS DEBUG ===\n",
      "categorical features (cols): ['cat_0', 'cat_1', 'cat_2']\n",
      "categorical features (array): 3\n",
      "numerical features (cols): ['num_0', 'num_1', 'num_2', 'num_3']\n",
      "numerical features (array): 4\n",
      "ðŸ–¥ï¸ GPU å¯ç”¨: NVIDIA GeForce RTX 3060\n",
      "ðŸ”¢ å¯ç”¨GPUæ•¸é‡: 1\n",
      "ðŸ’¾ GPUè¨˜æ†¶é«”: 12.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using current (post-sampling) data distribution for class weight computation\n",
      "Current class distribution: {0: 2877, 1: 769}\n",
      "Class 0: weight = 0.6336\n",
      "Class 1: weight = 2.3706\n",
      "Original class distribution (for reference): {0: 3231, 1: 769}\n",
      "Using class weights: [0.63364613 2.3706112 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./models/model_d0.0_b1.pth\n",
      "\n",
      "=== Training Set Evaluation ===\n",
      "Training Set Accuracy: 0.9506\n",
      "\n",
      "Training Set Confusion Matrix:\n",
      "[[2756  121]\n",
      " [  59  710]]\n",
      "Training Set ROC AUC: 0.9803\n",
      "âœ… è¨“ç·´é›†è©•ä¼°åœ–è¡¨å·²ä¿å­˜ç‚º 'model_d0.0_b1.pth_training_metrics.png'\n",
      "âœ… æ¨¡åž‹æª”æ¡ˆè¼‰å…¥æˆåŠŸ: ./models/model_d0.0_b1.pth\n",
      "âœ… æ¨¡åž‹æž¶æ§‹åŒ¹é…ï¼Œç›´æŽ¥è¼‰å…¥æˆåŠŸ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:846: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:947: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state = torch.load(f\"./models/{model_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6150\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74       829\n",
      "           1       0.19      0.39      0.26       171\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.52      0.53      0.50      1000\n",
      "weighted avg       0.73      0.61      0.66      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[548 281]\n",
      " [104  67]]\n",
      "\n",
      "Detailed Confusion Matrix:\n",
      "Predicted:       0       1\n",
      "Actual 0:     548     281\n",
      "Actual 1:     104      67\n",
      "æ··æ·†çŸ©é™£åœ–è¡¨å·²ä¿å­˜ç‚º 'confusion_matrix.png'\n",
      "Training model with dropout=0.0, num_attn_blocks=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:1065: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded gender: [0, 1]\n",
      "Encoded primary_diagnosis: [0, 1, 2, 3, 4]\n",
      "Encoded discharge_to: [0, 1, 2, 3]\n",
      "=== Feature Encoding Complete ===\n",
      "Numerical features: ['age', 'num_procedures', 'days_in_hospital', 'comorbidity_score']\n",
      "Categorical features (encoded): ['gender', 'primary_diagnosis', 'discharge_to']\n",
      "\n",
      "Sample of encoded data:\n",
      "  gender primary_diagnosis discharge_to\n",
      "0      1                 1            1\n",
      "1      1                 3            0\n",
      "2      0                 1            2\n",
      "3      0                 4            0\n",
      "4      0                 2            3\n",
      "ðŸ”„ Applying under sampling with method: tomek\n",
      "=== Applying tomek under sampling ===\n",
      "Original class distribution: {0: 3231, 1: 769}\n",
      "Imbalance ratio: 4.20\n",
      "Applying tomek under sampling...\n",
      "Attempting Tomek Links under sampling...\n",
      "After Tomek Links: 3646 samples\n",
      "Removed 354 samples\n",
      "New class distribution: {0: 2877, 1: 769}\n",
      "=== Under sampling results ===\n",
      "Final class distribution: {0: 2877, 1: 769}\n",
      "Training set size: 4000 -> 3646\n",
      "Samples removed: 354\n",
      "âœ… Under sampling successful using tomek method\n",
      "After under sampling - Training set size: 3646 (was 4000)\n",
      "train_df_train_csv shape after DataFrame creation: (3646, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 492.79it/s]\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train_df_train_csv_processed shape: (3646, 7)\n",
      "Final test_df_train_csv_processed shape: (1000, 7)\n",
      "=== END PREPROCESS DEBUG ===\n",
      "categorical features (cols): ['cat_0', 'cat_1', 'cat_2']\n",
      "categorical features (array): 3\n",
      "numerical features (cols): ['num_0', 'num_1', 'num_2', 'num_3']\n",
      "numerical features (array): 4\n",
      "ðŸ–¥ï¸ GPU å¯ç”¨: NVIDIA GeForce RTX 3060\n",
      "ðŸ”¢ å¯ç”¨GPUæ•¸é‡: 1\n",
      "ðŸ’¾ GPUè¨˜æ†¶é«”: 12.0 GB\n",
      "Using current (post-sampling) data distribution for class weight computation\n",
      "Current class distribution: {0: 2877, 1: 769}\n",
      "Class 0: weight = 0.6336\n",
      "Class 1: weight = 2.3706\n",
      "Original class distribution (for reference): {0: 3231, 1: 769}\n",
      "Using class weights: [0.63364613 2.3706112 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ./models/model_d0.0_b2.pth\n",
      "\n",
      "=== Training Set Evaluation ===\n",
      "Training Set Accuracy: 0.9871\n",
      "\n",
      "Training Set Confusion Matrix:\n",
      "[[2850   27]\n",
      " [  20  749]]\n",
      "Training Set ROC AUC: 0.9956\n",
      "âœ… è¨“ç·´é›†è©•ä¼°åœ–è¡¨å·²ä¿å­˜ç‚º 'model_d0.0_b2.pth_training_metrics.png'\n",
      "âœ… æ¨¡åž‹æª”æ¡ˆè¼‰å…¥æˆåŠŸ: ./models/model_d0.0_b2.pth\n",
      "âœ… æ¨¡åž‹æž¶æ§‹åŒ¹é…ï¼Œç›´æŽ¥è¼‰å…¥æˆåŠŸ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:846: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:947: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state = torch.load(f\"./models/{model_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6420\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77       829\n",
      "           1       0.18      0.32      0.23       171\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.51      0.51      0.50      1000\n",
      "weighted avg       0.72      0.64      0.68      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[588 241]\n",
      " [117  54]]\n",
      "\n",
      "Detailed Confusion Matrix:\n",
      "Predicted:       0       1\n",
      "Actual 0:     588     241\n",
      "Actual 1:     117      54\n",
      "æ··æ·†çŸ©é™£åœ–è¡¨å·²ä¿å­˜ç‚º 'confusion_matrix.png'\n",
      "Training model with dropout=0.0, num_attn_blocks=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\src\\ft_transformer.py:1065: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded gender: [0, 1]\n",
      "Encoded primary_diagnosis: [0, 1, 2, 3, 4]\n",
      "Encoded discharge_to: [0, 1, 2, 3]\n",
      "=== Feature Encoding Complete ===\n",
      "Numerical features: ['age', 'num_procedures', 'days_in_hospital', 'comorbidity_score']\n",
      "Categorical features (encoded): ['gender', 'primary_diagnosis', 'discharge_to']\n",
      "\n",
      "Sample of encoded data:\n",
      "  gender primary_diagnosis discharge_to\n",
      "0      1                 1            1\n",
      "1      1                 3            0\n",
      "2      0                 1            2\n",
      "3      0                 4            0\n",
      "4      0                 2            3\n",
      "ðŸ”„ Applying under sampling with method: tomek\n",
      "=== Applying tomek under sampling ===\n",
      "Original class distribution: {0: 3231, 1: 769}\n",
      "Imbalance ratio: 4.20\n",
      "Applying tomek under sampling...\n",
      "Attempting Tomek Links under sampling...\n",
      "After Tomek Links: 3646 samples\n",
      "Removed 354 samples\n",
      "New class distribution: {0: 2877, 1: 769}\n",
      "=== Under sampling results ===\n",
      "Final class distribution: {0: 2877, 1: 769}\n",
      "Training set size: 4000 -> 3646\n",
      "Samples removed: 354\n",
      "âœ… Under sampling successful using tomek method\n",
      "After under sampling - Training set size: 3646 (was 4000)\n",
      "train_df_train_csv shape after DataFrame creation: (3646, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 500.02it/s]\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ShiShiuan\\Desktop\\æ©Ÿå™¨å­¸ç¿’èˆ‡äººå·¥æ™ºæ…§å¯¦ä½œ\\venv\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train_df_train_csv_processed shape: (3646, 7)\n",
      "Final test_df_train_csv_processed shape: (1000, 7)\n",
      "=== END PREPROCESS DEBUG ===\n",
      "categorical features (cols): ['cat_0', 'cat_1', 'cat_2']\n",
      "categorical features (array): 3\n",
      "numerical features (cols): ['num_0', 'num_1', 'num_2', 'num_3']\n",
      "numerical features (array): 4\n",
      "ðŸ–¥ï¸ GPU å¯ç”¨: NVIDIA GeForce RTX 3060\n",
      "ðŸ”¢ å¯ç”¨GPUæ•¸é‡: 1\n",
      "ðŸ’¾ GPUè¨˜æ†¶é«”: 12.0 GB\n",
      "Using current (post-sampling) data distribution for class weight computation\n",
      "Current class distribution: {0: 2877, 1: 769}\n",
      "Class 0: weight = 0.6336\n",
      "Class 1: weight = 2.3706\n",
      "Original class distribution (for reference): {0: 3231, 1: 769}\n",
      "Using class weights: [0.63364613 2.3706112 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from src.ft_transformer import CustomerFTTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# 1. å®šç¾©è¶…åƒæ•¸ç©ºé–“\n",
    "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "num_attn_blocks_values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# 2. ç”¨ä¾†å­˜æ”¾çµæžœ\n",
    "results = []\n",
    "\n",
    "for dropout in dropout_values:\n",
    "    for num_attn_blocks in num_attn_blocks_values:\n",
    "        print(f\"Training model with dropout={dropout}, num_attn_blocks={num_attn_blocks}\")\n",
    "        \n",
    "        # 3. å»ºç«‹æ¨¡åž‹\n",
    "        model = CustomerFTTransformer(num_attn_blocks=num_attn_blocks, dropout=dropout)\n",
    "        \n",
    "        # 4. è³‡æ–™æº–å‚™èˆ‡é è™•ç†\n",
    "        model.format_dataframe()\n",
    "        model.preprocess(use_under_sampling=True, under_sampling_method='tomek')\n",
    "        model.set_feautres_processed()\n",
    "        model.set_tablar_dataset()\n",
    "        model.set_model_config()\n",
    "        \n",
    "        # 5. è¨“ç·´æ¨¡åž‹\n",
    "        model.train_model(num_epochs=500, model_name=f'model_d{dropout}_b{num_attn_blocks}.pth', use_class_weight=True)\n",
    "        \n",
    "        # 6. è©•ä¼°æ¨¡åž‹ï¼ˆå‡è¨­æœƒå›žå‚³ accuracy å’Œ cmï¼‰\n",
    "        accuracy, cm = model.evaluate_model(model_name=f'model_d{dropout}_b{num_attn_blocks}.pth')\n",
    "        \n",
    "        # 7. è¨˜éŒ„çµæžœ\n",
    "        results.append({\n",
    "            'dropout': dropout,\n",
    "            'num_attn_blocks': num_attn_blocks,\n",
    "            'accuracy': accuracy,\n",
    "            'cm': cm\n",
    "        })\n",
    "\n",
    "# 8. è½‰æˆ DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# 9. æ‰¾å‡ºæœ€ä½³åƒæ•¸çµ„åˆ\n",
    "best_row = df_results.loc[df_results['accuracy'].idxmax()]\n",
    "\n",
    "print(\"\\n===== Best Hyperparameters =====\")\n",
    "print(best_row)\n",
    "\n",
    "# 10. è¼¸å‡ºæ‰€æœ‰çµæžœè¡¨æ ¼ï¼ˆå¯é¸ï¼‰\n",
    "print(\"\\n===== All Results =====\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
