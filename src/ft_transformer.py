import numpy as np
from tqdm import tqdm

import torch

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import pandas as pd
import matplotlib.pyplot as plt

from torch.utils.data import Dataset, DataLoader
from torchkeras.tabular import TabularPreprocessor, TabularDataset
from torchkeras.tabular.models import FTTransformerConfig, FTTransformerModel

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from src.imbalance_data_processing import apply_smote, apply_under_sampling

from sklearn.preprocessing import LabelEncoder


np.random.seed(42)

# ----- æ•¸å€¼å‹èˆ‡é¡åˆ¥å‹ç‰¹å¾µ -----
NUMERICAL_FEATURES = ['age', 'num_procedures', 'days_in_hospital', 'comorbidity_score']
CATEGORICAL_FEATURES = ['gender', 'primary_diagnosis', 'discharge_to']
TARGET = 'readmitted'
NUMERICAL_COLUMNS = [f'num_{i}' for i in range(len(NUMERICAL_FEATURES))]
CATEGORICAL_COLUMNS = [f'cat_{i}' for i in range(len(CATEGORICAL_FEATURES))]

class CustomerFTTransformer:
    def __init__(self):
        self.scaler = StandardScaler()
        self.train_df = pd.read_csv("data/train_df.csv")
        self.test_df_test_csv = pd.read_csv("data/test_df.csv")

        # ä½¿ç”¨ TabularPreprocessor é€²è¡Œé è™•ç†
        self.preprocessor = TabularPreprocessor(
            cat_features=CATEGORICAL_COLUMNS,  # é¡åˆ¥ç‰¹å¾µ
            numeric_features=NUMERICAL_COLUMNS,    # æ•¸å€¼ç‰¹å¾µ
            normalization='standard',           # æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ–ï¼ˆå¯é¸ï¼š'minmax' æˆ– Noneï¼‰
            onehot_max_cat_num=1,
        )

        self.model_config = FTTransformerConfig(
            # ModelConfig åƒæ•¸
            task="classification",  # äºŒå…ƒåˆ†é¡
            num_attn_blocks=3,
        )

        self.model = None
        self.config = None
        self.train_df_train_csv_processed = None
        self.test_df_train_csv_processed = None
        self.train_target_df = None
        self.test_target_df = None
        self.train_df_train_csv = None
        self.test_df_train_csv = None
        self.numerical_features_processed = None
        self.embedding_features_processed = None
        self.ds_train = None
        self.ds_test = None
        self.dl_train = None
        self.dl_test = None

    def format_dataframe(self):
        # å°‡é¡åˆ¥ç‰¹å¾µç·¨ç¢¼ç‚ºæ•¸å€¼ï¼ˆSMOTENC éœ€è¦æ•´æ•¸å½¢å¼çš„é¡åˆ¥ç‰¹å¾µï¼‰
        self.label_encoders = {}
        
        for col in CATEGORICAL_FEATURES:
            le = LabelEncoder()
            self.train_df[col] = le.fit_transform(self.train_df[col])
            self.label_encoders[col] = le
            
            # è½‰æ›ç‚º category é¡å‹
            self.train_df[col] = self.train_df[col].astype('category')
            
            print(f"Encoded {col}: {self.train_df[col].cat.categories.tolist()}")

        self.train_df[TARGET] = self.train_df[TARGET].astype('category')
        
        print("=== Feature Encoding Complete ===")
        print(f"Numerical features: {NUMERICAL_FEATURES}")
        print(f"Categorical features (encoded): {CATEGORICAL_FEATURES}")
        
        # æª¢æŸ¥ç·¨ç¢¼å¾Œçš„æ•¸æ“šæ¨£æœ¬
        print("\nSample of encoded data:")
        print(self.train_df[CATEGORICAL_FEATURES].head())

    def _split_train_test(self):
        # è½‰æˆ numpy
        X_num = self.train_df[NUMERICAL_FEATURES].values.astype(np.float32)
        X_cat = self.train_df[CATEGORICAL_FEATURES].values
        y = self.train_df[TARGET].values.astype(np.int64)

        # åˆ†å‰²è¨“ç·´æ¸¬è©¦è³‡æ–™
        return train_test_split(
            X_num, X_cat, y, test_size=0.2, random_state=42
        )


    def preprocess(self, use_smote=False, use_under_sampling=False, smote_method='smotenc', under_sampling_method='tomek'):
        X_num_train, X_num_test, X_cat_train, X_cat_test, y_train, y_test = self._split_train_test()
        
        # ä¿å­˜åŸå§‹çš„ y_train ç”¨æ–¼ class weight è¨ˆç®—
        self.original_y_train = y_train.copy()
        
        # æ¨™æº–åŒ–æ•¸å€¼ç‰¹å¾µï¼ˆé€™å° SMOTE å¾ˆé‡è¦ï¼‰
        X_num_train = self.scaler.fit_transform(X_num_train)
        X_num_test = self.scaler.transform(X_num_test)

        # æª¢æŸ¥æ¡æ¨£æ–¹æ³•è¡çª
        if use_smote and use_under_sampling:
            print(f"Applying Under Sampling using: {under_sampling_method}, then applying SMOTE using: {smote_method}")

        # Apply Under Sampling if requested
        if use_under_sampling:
            print(f"ğŸ”„ Applying under sampling with method: {under_sampling_method}")
            X_num_train_orig_size = len(X_num_train)
            X_num_train, X_cat_train, y_train = apply_under_sampling(X_num_train, X_cat_train, y_train, method=under_sampling_method)
            print(f"After under sampling - Training set size: {len(y_train)} (was {X_num_train_orig_size})")

        # Apply SMOTE if requested (and not using under sampling)
        if use_smote:
            print(f"ğŸ”„ Applying SMOTE with method: {smote_method}")
            X_num_train_orig_size = len(X_num_train)
            X_num_train, X_cat_train, y_train = apply_smote(X_num_train, X_cat_train, y_train, method=smote_method)
            print(f"After SMOTE - Training set size: {len(y_train)} (was {X_num_train_orig_size})")
            print(f"After SMOTE - Class distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}")
            print(f"After SMOTE - X_num_train shape: {X_num_train.shape}")
            print(f"After SMOTE - X_cat_train shape: {X_cat_train.shape}")

        train_df_train_csv = pd.DataFrame({
            **{f'num_{i}': X_num_train[:, i] for i in range(X_num_train.shape[1])},
            **{f'cat_{i}': X_cat_train[:, i] for i in range(X_cat_train.shape[1])},
            'target': y_train
        })

        print(f"train_df_train_csv shape after DataFrame creation: {train_df_train_csv.shape}")

        test_df_train_csv = pd.DataFrame({
            **{f'num_{i}': X_num_test[:, i] for i in range(X_num_test.shape[1])},
            **{f'cat_{i}': X_cat_test[:, i] for i in range(X_cat_test.shape[1])},
            'target': y_test
        })

        self.train_target_df = train_df_train_csv['target']
        self.test_target_df = test_df_train_csv['target']

        self.train_df_train_csv = train_df_train_csv.drop(columns=['target'])
        self.test_df_train_csv = test_df_train_csv.drop(columns=['target'])

        self.preprocessor.fit(train_df_train_csv)
        train_df_train_csv_processed = self.preprocessor.transform(train_df_train_csv)
        test_df_train_csv_processed = self.preprocessor.transform(test_df_train_csv)

        self.train_df_train_csv_processed = train_df_train_csv_processed.loc[:, ~train_df_train_csv_processed.columns.duplicated(keep='last')]
        self.test_df_train_csv_processed = test_df_train_csv_processed.loc[:, ~test_df_train_csv_processed.columns.duplicated(keep='last')]

        print(f"Final train_df_train_csv_processed shape: {self.train_df_train_csv_processed.shape}")
        print(f"Final test_df_train_csv_processed shape: {self.test_df_train_csv_processed.shape}")
        print(f"=== END PREPROCESS DEBUG ===")

    # æª¢æŸ¥é¡åˆ¥åˆ†ä½ˆ
    def check_class_distribution(self, df:pd.DataFrame, target_col:str):
        """
        Check and print the class distribution of the target variable.
        
        Args:
            df (pd.DataFrame): Input dataframe to check
            target_col (str): Name of target column to analyze
            
        Returns:
            tuple: (value_counts, imbalance_ratio)
        """
        print("=== Class Distribution Analysis ===")
        
        # Get class distribution
        class_counts = df[target_col].value_counts().sort_index()
        print(f"Class distribution:")
        for class_val, count in class_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  Class {class_val}: {count} samples ({percentage:.2f}%)")
        
        # Calculate imbalance ratio
        min_class = class_counts.min()
        max_class = class_counts.max()
        imbalance_ratio = max_class / min_class
        print(f"Imbalance ratio: {imbalance_ratio:.2f}")
        
        if imbalance_ratio > 2.0:
            print("âš ï¸  Dataset is imbalanced.")
        else:
            print("âœ… Dataset is relatively balanced.")
        
        return class_counts, imbalance_ratio

    # è¨­å®šç‰¹å¾µè™•ç†
    def set_feautres_processed(self):
        self.numerical_features_processed = self.preprocessor.get_numeric_features()
        self.embedding_features_processed = self.preprocessor.get_embedding_features()
        
        # å°‡è³‡æ–™èˆ‡ç›®æ¨™è®Šæ•¸åˆä½µå¾Œé€²è¡Œ shuffle
        self.train_df_train_csv_processed['target'] = self.train_target_df
        self.test_df_train_csv_processed['target'] = self.test_target_df
        
        # å°è¨“ç·´è³‡æ–™é€²è¡Œ shuffle
        self.train_df_train_csv_processed = self.train_df_train_csv_processed.sample(
            frac=1, random_state=42
        ).reset_index(drop=True)
        
        # å°æ¸¬è©¦è³‡æ–™é€²è¡Œ shuffle 
        self.test_df_train_csv_processed = self.test_df_train_csv_processed.sample(
            frac=1, random_state=42
        ).reset_index(drop=True)

    # è¨­å®š TabularDataset
    def set_tablar_dataset(self):
        # === å»ºç«‹ TabularDataset ===
        self.ds_train = TabularDataset(
            data=self.train_df_train_csv_processed,
            task='classification',
            target=['target'],
            continuous_cols=self.numerical_features_processed,
            categorical_cols=self.embedding_features_processed
        )

        self.ds_test = TabularDataset(
            data=self.test_df_train_csv_processed,
            task='classification',
            target=['target'],
            continuous_cols=self.numerical_features_processed,
            categorical_cols=self.embedding_features_processed
        )

        self.dl_train = DataLoader(self.ds_train, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)
        self.dl_test = DataLoader(self.ds_test, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)

        print("categorical features (cols):", self.embedding_features_processed)
        print("categorical features (array):", self.train_df_train_csv_processed[self.embedding_features_processed].shape[1])
        print("numerical features (cols):", self.numerical_features_processed)
        print("numerical features (array):", self.train_df_train_csv_processed[self.numerical_features_processed].shape[1])

    # è¨­å®šæ¨¡å‹è¨­å®š
    def set_model_config(self):
        # å»ºç«‹æ¨¡å‹
        self.config = self.model_config.merge_dataset_config(self.ds_train)
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = FTTransformerModel(self.config)

    # è¨“ç·´æ¨¡å‹
    def train_model(self, num_epochs: int, model_name: str, use_class_weight=False, plot_train_metrics=True):
        """
        è¨“ç·´ FT-Transformer æ¨¡å‹
        
        Args:
            num_epochs (int): è¨“ç·´è¼ªæ•¸
            model_name (str): æ¨¡å‹ä¿å­˜åç¨±
            use_class_weight (bool): æ˜¯å¦ä½¿ç”¨ class weight ä¾†è™•ç†é¡åˆ¥ä¸å¹³è¡¡
            plot_train_metrics (bool): æ˜¯å¦åœ¨è¨“ç·´å¾Œç¹ªè£½è¨“ç·´é›†çš„ROCå’Œæ··æ·†çŸ©é™£
        """
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)
        
        # è¨ˆç®—ä¸¦è¨­å®š class weights
        if use_class_weight:
            class_weight_tensor = self._compute_class_weights(device)
            criterion = torch.nn.CrossEntropyLoss(weight=class_weight_tensor)
            print(f"Using class weights: {class_weight_tensor.cpu().numpy()}")
        else:
            criterion = torch.nn.CrossEntropyLoss()
            print("Using standard CrossEntropyLoss (no class weights)")

        self.model.to(device)
        self.model.train()

        progress_bar = tqdm(range(num_epochs), leave=False)
        for epoch in progress_bar:
            total_loss = 0
            for batch in self.dl_train:
                numerical = batch['continuous'].to(device)
                categorical = batch['categorical'].to(device)
                target = batch['target'].to(device).squeeze()
                optimizer.zero_grad()
                outputs = self.model({'continuous': numerical, 'categorical': categorical})
                logits = outputs['logits']
                loss = criterion(logits, target)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            
            progress_bar.set_description(f"Epoch {epoch+1}/{num_epochs} | Avg. Loss: {total_loss/len(self.dl_train):.4f}")
        
        # å„²å­˜æ¨¡å‹ï¼ˆå»ºè­°ç”¨ .pt æˆ– .pthï¼‰
        torch.save(self.model.state_dict(), f'./models/{model_name}')
        print(f"Model saved as ./models/{model_name}")
        
        # ç¹ªè£½è¨“ç·´é›†è©•ä¼°æŒ‡æ¨™
        if plot_train_metrics:
            print("\n=== Training Set Evaluation ===")
            self.evaluate_train_set()

    def evaluate_train_set(self):
        """
        è©•ä¼°è¨“ç·´é›†ä¸¦ç¹ªè£½ROCæ›²ç·šå’Œæ··æ·†çŸ©é™£
        """
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.model.eval()
        predictions = []
        probabilities = []
        true_labels = []
        
        with torch.no_grad():
            for batch in self.dl_train:
                numerical = batch['continuous'].to(device)
                categorical = batch['categorical'].to(device)
                target = batch['target'].to(device).squeeze()
                
                outputs = self.model({'continuous': numerical, 'categorical': categorical})
                logits = outputs['logits']
                
                # ç²å–é æ¸¬æ¦‚ç‡
                probs = torch.softmax(logits, dim=1)
                
                # ç²å–é æ¸¬é¡åˆ¥
                _, preds = torch.max(logits, dim=1)
                
                predictions.extend(preds.cpu().numpy())
                probabilities.extend(probs.cpu().numpy())
                true_labels.extend(target.cpu().numpy())
        
        # è½‰æ›ç‚ºnumpy arrays
        predictions = np.array(predictions)
        probabilities = np.array(probabilities)
        true_labels = np.array(true_labels)
        
        # è¨ˆç®—æº–ç¢ºç‡
        accuracy = accuracy_score(true_labels, predictions)
        print(f'Training Set Accuracy: {accuracy:.4f}')
        
        # é¡¯ç¤ºåˆ†é¡å ±å‘Š
        print('\nTraining Set Classification Report:')
        print(classification_report(true_labels, predictions))
        
        # è¨ˆç®—æ··æ·†çŸ©é™£
        cm = confusion_matrix(true_labels, predictions)
        print('\nTraining Set Confusion Matrix:')
        print(cm)
        
        # ç¹ªè£½æ··æ·†çŸ©é™£å’ŒROCæ›²ç·š
        self._plot_train_metrics(true_labels, predictions, probabilities, cm)
        
        return accuracy, cm

    def _plot_train_metrics(self, true_labels, predictions, probabilities, cm):
        """
        ç¹ªè£½è¨“ç·´é›†çš„ROCæ›²ç·šå’Œæ··æ·†çŸ©é™£
        
        Args:
            true_labels: çœŸå¯¦æ¨™ç±¤
            predictions: é æ¸¬æ¨™ç±¤
            probabilities: é æ¸¬æ¦‚ç‡
            cm: æ··æ·†çŸ©é™£
        """
        try:
            import seaborn as sns
            from sklearn.metrics import roc_curve, auc
            import matplotlib
            
            # è¨­å®šéäº’å‹•å¼å¾Œç«¯ï¼ˆé©ç”¨æ–¼æœå‹™å™¨ç’°å¢ƒï¼‰
            matplotlib.use('Agg')
            
            # è¨­å®šmatplotlibä¸­æ–‡å­—é«”
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'sans-serif']
            plt.rcParams['axes.unicode_minus'] = False
            
            # å‰µå»ºå­åœ–
            fig, axes = plt.subplots(1, 2, figsize=(15, 6))
            
            # === 1. ç¹ªè£½æ··æ·†çŸ©é™£ ===
            if len(np.unique(true_labels)) == 2:
                class_labels = ['Not Readmitted', 'Readmitted']
            else:
                class_labels = [f'Class {label}' for label in np.unique(true_labels)]
            
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
                       xticklabels=class_labels, 
                       yticklabels=class_labels,
                       ax=axes[0])
            axes[0].set_title("Training Set - Confusion Matrix", fontsize=14, fontweight='bold')
            axes[0].set_xlabel("Predicted", fontsize=12)
            axes[0].set_ylabel("Actual", fontsize=12)
            
            # === 2. ç¹ªè£½ROCæ›²ç·š ===
            if len(np.unique(true_labels)) == 2:  # äºŒå…ƒåˆ†é¡
                # ä½¿ç”¨æ­£é¡åˆ¥ï¼ˆclass 1ï¼‰çš„æ¦‚ç‡
                y_prob_positive = probabilities[:, 1]
                
                # è¨ˆç®—ROCæ›²ç·š
                fpr, tpr, thresholds = roc_curve(true_labels, y_prob_positive)
                roc_auc = auc(fpr, tpr)
                
                # ç¹ªè£½ROCæ›²ç·š
                axes[1].plot(fpr, tpr, color='darkorange', lw=3, 
                           label=f'ROC curve (AUC = {roc_auc:.4f})')
                axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                           label='Random Classifier', alpha=0.7)
                axes[1].set_xlim([0.0, 1.0])
                axes[1].set_ylim([0.0, 1.05])
                axes[1].set_xlabel('False Positive Rate', fontsize=12)
                axes[1].set_ylabel('True Positive Rate', fontsize=12)
                axes[1].set_title('Training Set - ROC Curve', fontsize=14, fontweight='bold')
                axes[1].legend(loc="lower right")
                axes[1].grid(True, alpha=0.3)
                
                print(f"Training Set ROC AUC: {roc_auc:.4f}")
            else:
                axes[1].text(0.5, 0.5, 'ROC curve only available\nfor binary classification', 
                           ha='center', va='center', transform=axes[1].transAxes, fontsize=12)
                axes[1].set_title('Training Set - ROC Curve (N/A)', fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜åœ–ç‰‡
            plt.savefig('training_metrics.png', dpi=300, bbox_inches='tight', facecolor='white')
            print("âœ… è¨“ç·´é›†è©•ä¼°åœ–è¡¨å·²ä¿å­˜ç‚º 'training_metrics.png'")
            
            # å˜—è©¦é¡¯ç¤ºåœ–ç‰‡ï¼ˆå¦‚æœåœ¨æ”¯æ´çš„ç’°å¢ƒä¸­ï¼‰
            try:
                plt.show()
            except:
                print("ğŸ“Š åœ–è¡¨å·²ç”Ÿæˆä¸¦ä¿å­˜ï¼Œä½†ç„¡æ³•åœ¨ç•¶å‰ç’°å¢ƒä¸­é¡¯ç¤º")
            
            # é—œé–‰åœ–å½¢ä»¥é‡‹æ”¾è¨˜æ†¶é«”
            plt.close(fig)
            
        except ImportError as e:
            print(f"âš ï¸ Warning: ç¼ºå°‘å¿…è¦å¥—ä»¶: {e}")
            print("è«‹å®‰è£å¿…è¦å¥—ä»¶: pip install seaborn scikit-learn matplotlib")
        except Exception as e:
            print(f"ç„¡æ³•å‰µå»ºè¨“ç·´é›†è©•ä¼°åœ–è¡¨: {e}")
            import traceback
            traceback.print_exc()

    def _compute_class_weights(self, device):
        """
        è¨ˆç®— class weights ç”¨æ–¼å¹³è¡¡è¨“ç·´
        
        Args:
            device: é‹ç®—è¨­å‚™ ('cuda' æˆ– 'cpu')
            
        Returns:
            torch.Tensor: class weights tensor
        """
        from sklearn.utils.class_weight import compute_class_weight
        
        # ä½¿ç”¨ç•¶å‰ï¼ˆç¶“éæ¡æ¨£å¾Œï¼‰çš„ y_train ä¾†è¨ˆç®— class weights
        y_for_weights = self.train_target_df.values
        print("Using current (post-sampling) data distribution for class weight computation")
        
        # ç²å–å”¯ä¸€é¡åˆ¥
        unique_classes = np.unique(y_for_weights)
        
        # è¨ˆç®— class weights
        class_weights = compute_class_weight(
            class_weight='balanced', 
            classes=unique_classes, 
            y=y_for_weights
        )
        
        # è½‰æ›ç‚º tensor
        class_weight_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)
        
        # è¼¸å‡º class weight è³‡è¨Š
        print(f"Current class distribution: {dict(zip(*np.unique(y_for_weights, return_counts=True)))}")
        for i, (class_label, weight) in enumerate(zip(unique_classes, class_weights)):
            print(f"Class {class_label}: weight = {weight:.4f}")
        
        # å¦‚æœæœ‰åŸå§‹è³‡æ–™åˆ†å¸ƒï¼Œä¹Ÿé¡¯ç¤ºå°æ¯”
        if hasattr(self, 'original_y_train'):
            original_distribution = dict(zip(*np.unique(self.original_y_train, return_counts=True)))
            print(f"Original class distribution (for reference): {original_distribution}")
        
        return class_weight_tensor

    def get_class_weights_info(self):
        """
        ç²å– class weights è³‡è¨Šï¼Œç”¨æ–¼èª¿è©¦
        
        Returns:
            dict: åŒ…å« class weights å’Œç›¸é—œè³‡è¨Šçš„å­—å…¸
        """
        from sklearn.utils.class_weight import compute_class_weight
        
        # ä½¿ç”¨ç•¶å‰ï¼ˆç¶“éæ¡æ¨£å¾Œï¼‰çš„è³‡æ–™åˆ†å¸ƒ
        if hasattr(self, 'train_target_df') and self.train_target_df is not None:
            y_for_weights = self.train_target_df.values
            print("Using current (post-sampling) data distribution for class weight computation")
        else:
            print("âš ï¸ Warning: train_target_df not found. Run preprocess() first.")
            return None
        
        unique_classes = np.unique(y_for_weights)
        class_weights = compute_class_weight(
            class_weight='balanced', 
            classes=unique_classes, 
            y=y_for_weights
        )
        
        unique, counts = np.unique(y_for_weights, return_counts=True)
        current_class_distribution = dict(zip(unique, counts))
        
        result = {
            'current_class_distribution': current_class_distribution,
            'class_weights': dict(zip(unique_classes, class_weights)),
            'imbalance_ratio': max(counts) / min(counts) if min(counts) > 0 else float('inf')
        }
        
        # å¦‚æœæœ‰åŸå§‹è³‡æ–™åˆ†å¸ƒï¼Œä¹Ÿæ·»åŠ åˆ°çµæœä¸­
        if hasattr(self, 'original_y_train'):
            original_unique, original_counts = np.unique(self.original_y_train, return_counts=True)
            result['original_class_distribution'] = dict(zip(original_unique, original_counts))
            result['original_imbalance_ratio'] = max(original_counts) / min(original_counts)
        
        return result

    # è©•ä¼°æ¨¡å‹
    def evaluate_model(self, model_name: str):
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.model = FTTransformerModel(config=self.config)
        self.model.load_state_dict(torch.load(f"./models/{model_name}"))
        self.model.to(device=device)        
        self.model.eval()
        
        predictions = []
        true_labels = []
        with torch.no_grad():
            for batch in self.dl_test:
                numerical = batch['continuous'].to(device)
                categorical = batch['categorical'].to(device)
                target = batch['target'].to(device).squeeze()
                outputs = self.model({'continuous': numerical, 'categorical': categorical})
                _, preds = torch.max(outputs['logits'], dim=1)
                predictions.extend(preds.cpu().numpy())
                true_labels.extend(target.cpu().numpy())
        
        # è¨ˆç®—æº–ç¢ºç‡
        accuracy = accuracy_score(true_labels, predictions)
        print(f'Test Accuracy: {accuracy:.4f}')
        
        # é¡¯ç¤ºåˆ†é¡å ±å‘Š
        print('\nClassification Report:')
        print(classification_report(true_labels, predictions))
        
        # é¡¯ç¤ºæ··æ·†çŸ©é™£
        print('\nConfusion Matrix:')
        cm = confusion_matrix(true_labels, predictions)
        print(cm)
        
        # å‰µå»ºæ›´è©³ç´°çš„æ··æ·†çŸ©é™£é¡¯ç¤º
        print('\nDetailed Confusion Matrix:')
        unique_labels = sorted(list(set(true_labels + predictions)))
        
        # æ‰“å°è¡¨é ­
        print('Predicted:', end='')
        for label in unique_labels:
            print(f'{label:>8}', end='')
        print()
        
        # æ‰“å°æ¯ä¸€è¡Œ
        for i, true_label in enumerate(unique_labels):
            print(f'Actual {true_label}:', end='')
            for j, pred_label in enumerate(unique_labels):
                print(f'{cm[i,j]:>8}', end='')
            print()
        
        # å¯é¸ï¼šå‰µå»ºè¦–è¦ºåŒ–çš„æ··æ·†çŸ©é™£
        self._plot_confusion_matrix(cm, unique_labels)
        
        return accuracy, cm
    
    def _plot_confusion_matrix(self, cm, labels):
        """
        ç¹ªè£½æ··æ·†çŸ©é™£çš„è¦–è¦ºåŒ–åœ–è¡¨
        """
        try:
            import seaborn as sns
            
            # è¨­å®šæ¨™ç±¤æ˜ å°„
            if len(labels) == 2:
                class_labels = ['Not Readmitted', 'Readmitted']
            else:
                class_labels = [f'Class {label}' for label in labels]
            
            plt.figure(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
                       xticklabels=class_labels, 
                       yticklabels=class_labels)
            plt.title("Confusion Matrix")
            plt.xlabel("Predicted")
            plt.ylabel("Actual")
            plt.tight_layout()
            plt.show()
            
            # åŒæ™‚ä¿å­˜åœ–ç‰‡
            plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
            print("æ··æ·†çŸ©é™£åœ–è¡¨å·²ä¿å­˜ç‚º 'confusion_matrix.png'")
            
        except ImportError:
            print("Seaborn æœªå®‰è£ï¼Œç„¡æ³•é¡¯ç¤ºè¦–è¦ºåŒ–æ··æ·†çŸ©é™£")
            print("è«‹å®‰è£ seaborn: pip install seaborn")
        except Exception as e:
            print(f"ç„¡æ³•å‰µå»ºè¦–è¦ºåŒ–æ··æ·†çŸ©é™£: {e}")

    # æ¸¬è©¦ test_df.csv æ¨¡å‹è©•ä¼°
    def test_csv_model_eval(self):
        # ä½¿ç”¨è¨“ç·´æ™‚çš„ LabelEncoder ä¾†ç·¨ç¢¼é¡åˆ¥ç‰¹å¾µ
        if hasattr(self, 'label_encoders'):
            for col in CATEGORICAL_FEATURES:
                # ä½¿ç”¨è¨“ç·´æ™‚ä¿å­˜çš„ LabelEncoder
                self.test_df_test_csv[col] = self.label_encoders[col].transform(self.test_df_test_csv[col])
                self.test_df_test_csv[col] = self.test_df_test_csv[col].astype('category')
        else:
            print("âš ï¸ Warning: No label encoders found. Run format_dataframe() first.")
            # å°‡é¡åˆ¥ç‰¹å¾µè½‰ç‚º category é¡å‹ï¼ˆåŸæœ‰é‚è¼¯ï¼‰
            for col in CATEGORICAL_FEATURES:
                self.test_df_test_csv[col] = self.test_df_test_csv[col].astype('category')

        # ä½¿ç”¨è¨“ç·´æ™‚çš„ scaler ä¾†æ¨™æº–åŒ–æ¸¬è©¦æ•¸æ“š
        X_num_test_csv = self.test_df_test_csv[NUMERICAL_FEATURES].values.astype(np.float32)
        X_num_test_csv = self.scaler.transform(X_num_test_csv)  # ä½¿ç”¨å·²ç¶“ fit çš„ scaler
        X_cat_test_csv = self.test_df_test_csv[CATEGORICAL_FEATURES].values

        self.test_df_test_csv = pd.DataFrame({
            **{f'num_{i}': X_num_test_csv[:, i] for i in range(X_num_test_csv.shape[1])},
            **{f'cat_{i}': X_cat_test_csv[:, i] for i in range(X_cat_test_csv.shape[1])},
        })

        test_df_test_csv_processed = self.preprocessor.transform(self.test_df_test_csv)
        test_df_test_csv_processed = test_df_test_csv_processed.loc[:, ~test_df_test_csv_processed.columns.duplicated(keep='last')]

        ds_test_test_csv = TabularDataset(
            data=test_df_test_csv_processed,
            task='classification',
            continuous_cols=self.numerical_features_processed,
            categorical_cols=self.embedding_features_processed
        )

        dl_test_test_csv = DataLoader(ds_test_test_csv, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = FTTransformerModel(config=self.config)
        self.model.load_state_dict(torch.load("ft_transformer_model.pth"))
        self.model.to(device)

        predictions = []

        # evaluation mode
        self.model.eval()
        with torch.no_grad():
            for batch in dl_test_test_csv:
                numerical = batch['continuous'].to(device)
                categorical = batch['categorical'].to(device)
                outputs = self.model({'continuous': numerical, 'categorical': categorical})
                _, preds = torch.max(outputs['logits'], dim=1)
                predictions.extend(preds.cpu().numpy())

        submission_df = pd.DataFrame({
            "Patient_ID": range(1, len(predictions)+1),
            "readmitted": predictions
        })

        submission_df.to_csv(path_or_buf='data/submission_df.csv', index=False)

    def plot_train_roc_and_confusion_matrix(self, model_name=None):
        """
        å–®ç¨ç¹ªè£½è¨“ç·´é›†çš„ROCæ›²ç·šå’Œæ··æ·†çŸ©é™£ï¼ˆç„¡éœ€é‡æ–°è¨“ç·´ï¼‰
        
        Args:
            model_name (str, optional): å¦‚æœæä¾›ï¼Œæœƒè¼‰å…¥æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶
        """
        if model_name:
            # è¼‰å…¥æŒ‡å®šçš„æ¨¡å‹
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.model = FTTransformerModel(config=self.config)
            self.model.load_state_dict(torch.load(f"./models/{model_name}"))
            self.model.to(device)
            print(f"Model loaded from ./models/{model_name}")
        
        if self.model is None:
            print("âš ï¸ Error: No model available. Please train a model first or provide model_name.")
            return None
        
        print("ğŸ” Evaluating training set...")
        return self.evaluate_train_set()